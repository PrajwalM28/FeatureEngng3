{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33618b28-aec8-44c8-926d-e592f0ea1cd9",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "### What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1d19c-e79c-494b-bf77-c58113d1804e",
   "metadata": {},
   "source": [
    "-  Min-Max scaling, also known as normalization, is a technique used to scale and transform the values of a feature to a specific range, usually between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db32183-6a71-4cf6-8ae1-2621f4fa10c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature  feature_scaled\n",
      "0        2        0.000000\n",
      "1        5        0.166667\n",
      "2       10        0.444444\n",
      "3       15        0.722222\n",
      "4       20        1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = {'feature': [2, 5, 10, 15, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['feature_scaled'] = scaler.fit_transform(df[['feature']])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc33321-0640-4798-8f7c-3f85dd87d484",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "###  What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577d98f-7dba-4c99-ae54-2cf759999b73",
   "metadata": {},
   "source": [
    "- The Unit Vector technique, also known as normalization or vector normalization, scales the values of a feature to a unit vector, where the magnitude of the vector becomes 1. \n",
    "\n",
    "- The difference between Min-Max scaling and Unit Vector scaling lies in the range of the scaled values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebfe0ce-e45a-468c-97c9-003a7cb8eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature  feature_unit\n",
      "0        2      0.072836\n",
      "1        5      0.182089\n",
      "2       10      0.364179\n",
      "3       15      0.546268\n",
      "4       20      0.728357\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "data = {'feature': [2, 5, 10, 15, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['feature_unit'] = normalize(df[['feature']], axis=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69984c3e-3d9a-494f-ba3f-8d1c456e993c",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "###  What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2fd61-5c0a-4405-bb2d-bb270ac43ebc",
   "metadata": {},
   "source": [
    "- Principal Component Analysis (PCA) is a dimensionality reduction technique that aims to transform the original features of a dataset into a new set of uncorrelated features, called principal components. These components are ordered by the amount of variance they capture, allowing for a reduction in the dimensionality of the dataset while retaining as much variance as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27a2c9f-225d-4dc4-9bea-bca30c00a2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  pca_component\n",
      "0         1         5       2.828427\n",
      "1         2         4       1.414214\n",
      "2         3         3      -0.000000\n",
      "3         4         2      -1.414214\n",
      "4         5         1      -2.828427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = {'feature1': [1, 2, 3, 4, 5],\n",
    "        'feature2': [5, 4, 3, 2, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "df['pca_component'] = pca.fit_transform(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92c36b-6b1f-43a1-a23d-755634608dc5",
   "metadata": {},
   "source": [
    "# Q4.\n",
    "### What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb4ca0-53ce-4b97-bab7-1d4965a77e9a",
   "metadata": {},
   "source": [
    "- PCA is a technique commonly used for Feature Extraction, a process of transforming the original features of a dataset into a new set of features (principal components) with reduced dimensionality. These principal components capture the most significant information in the data while minimizing redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1bac857-18f1-40a1-8400-5ec93344a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  pca_component\n",
      "0         1         5       2.828427\n",
      "1         2         4       1.414214\n",
      "2         3         3      -0.000000\n",
      "3         4         2      -1.414214\n",
      "4         5         1      -2.828427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = {'feature1': [1, 2, 3, 4, 5],\n",
    "        'feature2': [5, 4, 3, 2, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "df['pca_component'] = pca.fit_transform(df[['feature1', 'feature2']])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b1563-c79c-4ee1-b888-707774846cd2",
   "metadata": {},
   "source": [
    "# Q5.\n",
    "### You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa96e5-8db3-4e53-a73c-a28999222bc6",
   "metadata": {},
   "source": [
    "- Identify numerical features\n",
    "- Apply Min-Max Scaling Formula \n",
    "- Implement Range Adjustment\n",
    "- Repeat for Each Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d7b20-93a7-438b-9b03-8b6031d63805",
   "metadata": {},
   "source": [
    "# Q6.\n",
    "### You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30a79a-6d78-4e86-a86c-f35998bec1d3",
   "metadata": {},
   "source": [
    "- Identify numerical features\n",
    "- Apply Min-Max Scaling Formula \n",
    "- Implement Range Adjustment\n",
    "- Repeat for Each Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac7b22-e023-46d9-ac89-fc749f345189",
   "metadata": {},
   "source": [
    "# Q7.\n",
    "### For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c246a2-16cb-41cf-bf54-69709a98356e",
   "metadata": {},
   "source": [
    "- Identify min_val and max_val : min_val = 1 , max_val = 20\n",
    "- Apply the formula ,\n",
    "\n",
    "X scaled = X−min_val/max_val−min_val ×(new_max−new_min)+new_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee16374-efa6-4444-ab3a-5c0d15ef7957",
   "metadata": {},
   "source": [
    "# Q8.\n",
    "### For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefb088-58fd-4140-9765-cf6472ffda26",
   "metadata": {},
   "source": [
    "- Standardize the Data: Before applying PCA, it's essential to standardize the data by subtracting the mean and dividing by the standard deviation for each feature.\n",
    "\n",
    "- Apply PCA: Apply PCA to identify the principal components. These components capture the maximum variance in the dataset.\n",
    "\n",
    "- Determine the Number of Components: Decide on the number of principal components to retain based on the explained variance. You can plot the cumulative explained variance and choose a sufficient number of components to retain a high percentage of the total variance (e.g., 95% or more)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
